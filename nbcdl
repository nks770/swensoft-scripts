#!/bin/env python3

import argparse
import json
import re
#import subprocess
#from pathlib import Path
import urllib.request
from bs4 import BeautifulSoup

# Parse arguments
parser = argparse.ArgumentParser(description='Download/archive an NBC video stream.')
parser.add_argument('url',metavar='url',nargs=1,default='',
                    help='URL of video to download.')
args = parser.parse_args()
url = args.url[0]


# Verify provided URL
link = re.split(r'(?x)^(?:https)?:?\/\/((?:www\.)?(?:nbcnews)\.com)\/([^\/]+)\/([^\/]+)\/((.+)-(.+))$',url)
type = 'nbcnews'

if len(link)<8:
  link = re.split(r'(?x)^(?:https)?:?\/\/((?:www\.)?(?:nbc)\.com)\/([^\/]+)\/([^\/]+)\/((.+)\/(.+))$',url)
  type = 'nbc'

clean_url = 'https://{}/{}/{}/{}'.format(link[1],link[2],link[3],link[4])

if len(link)<8:
  raise Exception("Unhandled URL pattern.")


# Download webpage
user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'
headers = {'User-Agent': user_agent}
req = urllib.request.Request(clean_url, data=None, headers=headers)
with urllib.request.urlopen(req) as response:
  webpage = response.read()
  soup = BeautifulSoup(webpage,features='html.parser')

nextdata = soup.find(attrs={'id':'__NEXT_DATA__'}).string
jsondata = json.loads(nextdata)

print(json.dumps(jsondata,indent=2))
